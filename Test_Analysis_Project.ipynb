{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real-word Trade-in Values of Car Brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for keyword: #ChinaVirus\n",
      "Scraped data have been exported to the csv file\n"
     ]
    }
   ],
   "source": [
    "# This code shows how to scrape twitter by using the snscrape python API\n",
    "# Please make sure the snscrape has been installed in the local environment\n",
    "# The snscape package can be installed by: pip3 install git+https://github.com/JustAnotherArchivist/snscrape.git\n",
    "# The Python version has to be greater than 3.8\n",
    "# An alternative Python method is to to execute CLI commands in Python. \n",
    "# Please check this link for more details: https://colab.research.google.com/drive/1ugr1biGxV9C2OwzS3HEh3KM0z2Xg44jb?usp=sharing\n",
    "\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "\n",
    "key_word = \"#ChinaVirus\"  # Declare the key word used to search tweets\n",
    "from_date = \"2020-03-10\" # Declare a start date\n",
    "end_date = '2020-03-17'  # Declare a end date\n",
    "count = 500          # The maximum number of tweets\n",
    "tweets_list_keyword = [] # A list used to store the returned results for keyword search\n",
    "tweets_list_user = []    # A list used to store the retuned results for user search\n",
    "\n",
    "\n",
    "#### Scraping tweets from a text search query ####\n",
    "command_keyword = key_word+' since:'+from_date+' until:'+end_date # Define a string command for Scraper Api\n",
    "print(\"Scraping data for keyword:\",key_word)\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(command_keyword).get_items()):\n",
    "    tweets_list_keyword.append([tweet.id, tweet.content, tweet.user.username, tweet.user.followersCount,tweet.user.listedCount,tweet.retweetedTweet]) # Append returned results to list\n",
    "    if i>count:\n",
    "        break;\n",
    "#Create a dataframe from the tweets list above \n",
    "tweets_df_keyword = pd.DataFrame(tweets_list_keyword, columns=['Tweet Id', 'Text', 'Username', 'followers','listedcount','retweeted'])\n",
    "tweets_df_keyword.to_csv(\"before_318.csv\",index=False) # Export to a csv file\n",
    "print(\"Scraped data have been exported to the csv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping data for keyword: #ChinaVirus\n"
     ]
    }
   ],
   "source": [
    "key_word = \"#ChinaVirus\"  # Declare the key word used to search tweets\n",
    "from_date = \"2020-03-18\" # Declare a start date\n",
    "end_date = '2020-03-24'  # Declare a end date\n",
    "count = 500          # The maximum number of tweets\n",
    "tweets_list_keyword = [] # A list used to store the returned results for keyword search\n",
    "tweets_list_user = []    # A list used to store the retuned results for user search\n",
    "\n",
    "\n",
    "#### Scraping tweets from a text search query ####\n",
    "command_keyword = key_word+' since:'+from_date+' until:'+end_date # Define a string command for Scraper Api\n",
    "print(\"Scraping data for keyword:\",key_word)\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper(command_keyword).get_items()):\n",
    "    tweets_list_keyword.append([tweet.id, tweet.content, tweet.user.username, tweet.user.followersCount,tweet.user.listedCount,tweet.retweetedTweet]) # Append returned results to list\n",
    "    if i>count:\n",
    "        break;\n",
    "#Create a dataframe from the tweets list above \n",
    "tweets_df_keyword = pd.DataFrame(tweets_list_keyword, columns=['Tweet Id', 'Text', 'Username', 'followers','listedcount','retweeted'])\n",
    "tweets_df_keyword.to_csv(\"after_318.csv\",index=False) # Export to a csv file\n",
    "print(\"Scraped data have been exported to the csv file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "path = Path.cwd() # current working directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text = tweets_df_keyword.Text.to_list()\n",
    "non_tweet_users = []\n",
    "for t in text:\n",
    "    \n",
    "    non_tweet_users.append(re.findall(r'[#]\\S*', t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_tweet_users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Scrapping data and process the data using NLTK "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping latest 5000 posts and store in post_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_text=[]\n",
    "for i in range(994,1095):\n",
    "    url='https://forums.edmunds.com/discussion/1212/general/x/real-world-trade-in-values/p'+str(i)\n",
    "    page=requests.get(url)\n",
    "    page_text=page.text\n",
    "    soup=BeautifulSoup(page_text, 'html.parser')\n",
    "    post_text_elem= soup.find_all(class_=\"Message userContent\")\n",
    "    for item in post_text_elem:\n",
    "        post_text.append(item.text.lstrip())\n",
    "post_text = post_text[35:5035]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize/remove stopwords/lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenizer(words) -> list:\n",
    "    tokenizer = RegexpTokenizer(r'[\\w-]+')\n",
    "    tokens = tokenizer.tokenize(words.lower())\n",
    "\n",
    "    stopwords_set = set(stopwords.words('english')) # use build in english package\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    return [lemmatizer.lemmatize(token, pos='v') for token in tokens if token not in stopwords_set]\n",
    "\n",
    "#apply tokenizer function to each post, using set to remove the repeat and store in processed text\n",
    "processed_text = []\n",
    "for comment in post_text:\n",
    "    processed_text.append(list(set(tokenizer(comment))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Find the top 10 brands from frequency counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Note:}$ Some people just use model name of a car instead of mentioning the brand name. Thus, we choose to convert the model name to the brand name and count frequency of each brand based on the converted text.\n",
    "\n",
    "To do so, we created a model_csv that stores the informaiton of car brand and the popular models under the brands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model_csv and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid = pd.read_csv(path.joinpath('models.csv'))\n",
    "\n",
    "model_grid['Brands'] = model_grid['Brands'].str.lower()\n",
    "model_grid['model']  = model_grid['model'].str.lower()\n",
    "model_grid = model_grid[['Brands','model']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate model frequency  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the model with its brand in the processed_text\n",
    "remove_dup = []\n",
    "for comment in processed_text: \n",
    "    for i in range(len(comment)): \n",
    "        if comment[i] in model_grid.model.tolist():\n",
    "            condition = model_grid['model'] == comment[i]\n",
    "            brand_index = model_grid.index[condition].tolist()\n",
    "            comment[i] = model_grid['Brands'].iloc[brand_index[0]]\n",
    "    remove_dup.append(list(set(comment)))\n",
    "fre = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in remove_dup:\n",
    "    for w in p:\n",
    "        if w in model_grid.Brands.tolist():\n",
    "            fre[w] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the brand frequency to dataframe and keep the top 10 brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_frequency = dict(fre)\n",
    "br = brand_frequency.keys()\n",
    "fre = brand_frequency.values()\n",
    "df = pd.DataFrame()\n",
    "df['brand'] = br\n",
    "df['frequency'] = fre\n",
    "\n",
    "#include top 10 brand and its frequency\n",
    "top = df.sort_values(by = 'frequency', ascending= False).head(10)\n",
    "\n",
    "#top 10 brand\n",
    "top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10 = top.brand.tolist() ## create list that record the name of top 10 brand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Calculate lift ratios for associations between top 10 brands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the combination of 10 brands to calculate the lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "comb = list(combinations(top_10,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sub-dataframe to store the model for top10 brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df = model_grid[model_grid['Brands'].isin(top_10)]\n",
    "target_df = target_df.reset_index(drop = True)\n",
    "target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace the model with its brand in the processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for comment in processed_text: \n",
    "    for i in range(len(comment)): \n",
    "        if comment[i] in target_df.model.tolist():\n",
    "            condition = target_df['model'] == comment[i]\n",
    "            brand_index = target_df.index[condition].tolist()\n",
    "            comment[i] = target_df['Brands'].iloc[brand_index[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a narrowed list of the posts that contains target brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_comment = []\n",
    "for comment in processed_text:\n",
    "    for words in comment:\n",
    "        if words in top_10:\n",
    "            target_comment.append(list(set(comment)))\n",
    "#remove duplicate\n",
    "target_comment_distinct = []\n",
    "for i in target_comment:\n",
    "    if i not in target_comment_distinct:\n",
    "        target_comment_distinct.append(i)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the #(A,B) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_frequency = {}\n",
    "for i in comb:\n",
    "    pair_frequency[i] = 0\n",
    "for pair in comb:\n",
    "    for comm in target_comment_distinct:\n",
    "        if pair[0] in comm and pair[1] in comm:\n",
    "            pair_frequency[pair] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lift = defaultdict(int)\n",
    "for i in pair_frequency.keys():\n",
    "    lift[i] = (5000*pair_frequency[i]) / (brand_frequency[i[0]]*brand_frequency[i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in lift:\n",
    "    if lift[i] == 0: ## some time two brand has not been mentioned together at all,we need to set a base value for lift\n",
    "        lift[i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lifts = pd.DataFrame(columns=top_10,index=top_10)\n",
    "for brand in top_10: \n",
    "    df_lifts[brand][brand] = '-'\n",
    "for brands in lift:\n",
    "    a,b = brands\n",
    "    df_lifts[a][b] = (lift[brands])\n",
    "    df_lifts[b][a] = '-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_brand_lifts = pd.DataFrame(columns=top_10,index=top_10)\n",
    "for brands in lift:\n",
    "    a,b = brands\n",
    "    top_brand_lifts[a][b] = (1/lift[brands])\n",
    "    top_brand_lifts[b][a] = (1/lift[brands])\n",
    "for brand in top_10: \n",
    "    top_brand_lifts[brand][brand] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_brand_lifts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task:  Plot the top 10 brands on a multidimensional scaling (MDS) map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import manifold\n",
    "import matplotlib.pyplot as plt\n",
    "mds = manifold.MDS(dissimilarity='euclidean',random_state=522)\n",
    "mds_fit = mds.fit(top_brand_lifts)\n",
    "coords = mds.fit_transform(top_brand_lifts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = coords.T\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(x,y)\n",
    "\n",
    "for i, txt in enumerate(top_10):\n",
    "    plt.annotate(txt, (x[i], y[i]), xycoords='data',\n",
    "             xytext=(20, -20), textcoords='offset points',\n",
    "             size=13, ha='right', va=\"center\",\n",
    "             bbox=dict(boxstyle=\"round\", alpha=0.1),\n",
    "             arrowprops=dict(arrowstyle=\"wedge,tail_width=0.5\", alpha=0.1))\n",
    "    \n",
    "plt.yticks([])\n",
    "plt.xticks([])\n",
    "plt.title('Multidimensional Scaling: Top 10 Brands \\n (Euclidean Distances = 1 / lift)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Task: Offer insights to two top 10 brands based on the analysis above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our analysis of the real-trade-in value forum on Edmunds.com, Volkswagen and Chevrolet appear to have the highest lift (3.25), which means that there’s a positive association between these two brands. Chevrolet is more likely to be mentioned in conjunction with Volkswagen than other brands. The frequency of occurrence of Chevrolet and Volkswagen is 40 among the total comments scraped.\n",
    "\n",
    "One of the possible reasons for such a high co-occurrence of these 2 brands in comments is that they have either very similar or very different trade-in values. When people discuss trade-in values, they tend to mention both of these brands at the same time to make comparisons. Therefore, brand managers of both Volkswagen and Chevrolet should be aware that the other brand is a potential competitor in the used car market. Some buyers who want to change hands their cars shortly might consider the trade-in values when buying the new car. Potential adjustments in production or after-sales service may affect the trade-in value, thus affecting the sales and profits.\n",
    "\n",
    "According to our research of the two brands, we found that they have overlapped target markets. Although these two brands may have different strategies in the new car market, when it comes to used car sales, customers’ standards tend to become similar. And sometimes, the trade-in value would also become an important feature. Especially for target customers of Volkswagen and Chevrolet, the age range indicates they may be in a stage that is not that stable and face the trade-in in the near future such as single to married or married to have children. Therefore, it is worth thinking for the brand managers of Volkswagen and Chevrolet that the higher trade-in value/reliability can become a selling point for those customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Analyze most frequently mentioned attributes of cars in the discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the most frequently mentioned attributes of cars in the discussions, we then look for the attributes from the narrowed list of the posts that contains brand (the target comment we got in previous section).\n",
    "\n",
    "But rather than using this list directly, we remove the verbs, conjunctions and prepositions using the tagging feature of NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging words in target comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "for i in range(len(target_comment)):\n",
    "    for j in range(len(target_comment[i])):\n",
    "        wordlist.append(target_comment[i][j])\n",
    "text = ' '.join(wordlist).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## list of noun and adj words\n",
    "n_adj_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS' \n",
    "                                             or pos == 'VBD' or pos == 'JJ' or pos == 'JJR' or pos == 'JJS'\n",
    "                                             or pos =='RB' or pos =='RBR'or pos =='RBS')]\n",
    "## list of adj only\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we did a word cloud based on the noun and adjs in the selecteed posts, to have a brief idea of the attributes that have involved in the discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_adj_string=(\" \").join(n_adj_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the frequency of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count the words frequency and sort\n",
    "from collections import Counter\n",
    "counts = Counter(n_adj_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Create the list of attribute based on the frequently mentioned words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After counting the occurrences of each selected word, ranked them by the number of occurrences. We manually selected meaningful descriptive words for cars and categorized them into 11 attributes: range, performance, comfort, vehicle architecture, safety, drivability, interior, sound, thermal management, energy management, appearance, and cost efficiency. (Reference of the attribute and how they have been categorized:https://www.avl.com/-/vehicle-attributes)\n",
    "\n",
    "Since we have already counted the occurrences of each particular word that describes vehicles, we summed up the number of occurrences of each word under each of the attribute categories to get the frequency of each attribute.\n",
    "\n",
    "The result was inputed into a attribute.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import attributes csv\n",
    "attributes = pd.read_csv(path.joinpath('attributes.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Find attributes that are most strongly associated with top 5 brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = attributes[['range_f', 'performance_f', 'comfort_f', 'vehicle_architecture_f','safety_f', 'drivability_f', 'interior_sound_f', 'thermal_management_f', 'energy_management_f', 'appearance_f','cost_efficiency_f']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "attr = s.sort_values(ascending=False)\n",
    "attr = pd.DataFrame({'attributes':attr.index, 'frequency':attr.values})\n",
    "attr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 5 car brands' frequency and lift for attributes that mentioned in the discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##From TASK A we get the most frequently mentioned brands are:\n",
    "top5 = df.sort_values(by = 'frequency', ascending= False).head(5)\n",
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "attlist = []\n",
    "brandlist = []\n",
    "for i in attr['attributes']:\n",
    "    attlist.append(i)\n",
    "    \n",
    "for i in top5['brand']:\n",
    "    brandlist.append(i) \n",
    "\n",
    "all_combinations = list(itertools.product(brandlist, attlist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com = []\n",
    "for i in range(len(all_combinations)):\n",
    "    com.append(all_combinations[i])\n",
    "\n",
    "#to remove duplicated combinations\n",
    "com = list(set(com))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Calculate the lift values for each pair of (brand, attribute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the frequency #(Brand, attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "comment_copy = copy.deepcopy(target_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to replace each specific attribute words with attributes categories in the text\n",
    "\n",
    "for j in range(len(target_comment)):\n",
    "    for i in range(len(target_comment[j])):\n",
    "        if target_comment[j][i] in attributes.cost_efficiency.dropna().tolist():\n",
    "            target_comment[j][i] = 'cost_efficiency_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.appearance.dropna().tolist():\n",
    "            target_comment[j][i] = 'appearance_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.drivability.dropna().tolist():\n",
    "            target_comment[j][i] = 'drivability_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.range.dropna().tolist():\n",
    "            target_comment[j][i] = 'range_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.vehicle_architecture.dropna().tolist():\n",
    "            target_comment[j][i] = 'vehicle_architecture_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.performance.dropna().tolist():\n",
    "            target_comment[j][i] = 'performance_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.comfort.dropna().tolist():\n",
    "            target_comment[j][i] = 'comfort_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.safety.dropna().tolist():\n",
    "            target_comment[j][i] = 'safety_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes['interior_sound'].tolist():\n",
    "            target_comment[j][i] = 'interior_sound_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.thermal_management.dropna().tolist():\n",
    "            target_comment[j][i] = 'thermal_managemen_f'\n",
    "            continue\n",
    "        if target_comment[j][i] in attributes.energy_management.dropna().tolist():\n",
    "            target_comment[j][i] = 'energy_management_f'\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Calculate the frequency #(Brand, attribute)\n",
    "pair_f = defaultdict(int)\n",
    "for pair in com:\n",
    "\n",
    "    for comment in target_comment:\n",
    "        if pair[0] in comment and pair[1] in comment:\n",
    "\n",
    "            pair_f[pair] +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store into a dictionary\n",
    "brand_dict = {}\n",
    "for (key, value) in brand_frequency.items():\n",
    "    if key in top5.brand.tolist():\n",
    "        brand_dict[key] = value\n",
    "att_dict = dict(zip(attr.attributes, attr.frequency))\n",
    "att_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Calculate Lift\n",
    "liftC = defaultdict(int)\n",
    "for i in pair_f.keys():\n",
    "    \n",
    "    liftC[i] = (5000*pair_f[i]) / (brand_dict[i[0]]*att_dict[i[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe that store the lift values for each brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_attr_lift = pd.DataFrame(columns=[\"attribute\",\"Lift\"])\n",
    "for i in liftC.keys():\n",
    "    if i[0] == 'honda':\n",
    "        honda_attr_lift = honda_attr_lift.append({'attribute': i[1], 'Lift': liftC[i]}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_attr_lift = honda_attr_lift.sort_values(by = 'Lift', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_attr_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_attr_lift = pd.DataFrame(columns=[\"attribute\",\"Lift\"])\n",
    "for i in liftC.keys():\n",
    "    if i[0] == 'chevrolet':\n",
    "        chevrolet_attr_lift = chevrolet_attr_lift.append({'attribute': i[1], 'Lift': liftC[i]}, ignore_index=True)\n",
    "\n",
    "chevrolet_attr_lift = chevrolet_attr_lift.sort_values(by = 'Lift', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_attr_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_attr_lift = pd.DataFrame(columns=[\"attribute\",\"Lift\"])\n",
    "for i in liftC.keys():\n",
    "    if i[0] == 'toyota':\n",
    "        toyota_attr_lift = toyota_attr_lift.append({'attribute': i[1], 'Lift': liftC[i]}, ignore_index=True)\n",
    "\n",
    "toyota_attr_lift = toyota_attr_lift.sort_values(by = 'Lift', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_attr_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_attr_lift = pd.DataFrame(columns=[\"attribute\",\"Lift\"])\n",
    "for i in liftC.keys():\n",
    "    if i[0] == 'ford':\n",
    "        ford_attr_lift = ford_attr_lift.append({'attribute': i[1], 'Lift': liftC[i]}, ignore_index=True)\n",
    "\n",
    "ford_attr_lift = ford_attr_lift.sort_values(by = 'Lift', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_attr_lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_attr_lift = pd.DataFrame(columns=[\"attribute\",\"Lift\"])\n",
    "for i in liftC.keys():\n",
    "    if i[0] == 'fiat':\n",
    "        fiat_attr_lift = fiat_attr_lift.append({'attribute': i[1], 'Lift': liftC[i]}, ignore_index=True)\n",
    "\n",
    "fiat_attr_lift = fiat_attr_lift.sort_values(by = 'Lift', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_attr_lift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Analyze attribute detail of top 5 brand and provide insights to product manager, and marketing/advertising team of the brands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import detail_attribute dataset. This is just a csv with a list of uncateforized attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detial_attributes = pd.read_csv(path.joinpath('detail_attribute.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detial_attributes = detial_attributes.detail_attribute.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Honda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filter out honda related comment\n",
    "honda_comment = []\n",
    "for comment in comment_copy:\n",
    "    if 'honda' in comment:\n",
    "        honda_comment.append(list(set(comment)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculate the frequency of each detailed attribute\n",
    "honda_attr = defaultdict(int)\n",
    "for comment in honda_comment:\n",
    "    for attr in detial_attributes:\n",
    "        if attr in comment:\n",
    "\n",
    "            honda_attr[attr] +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_attr = pd.DataFrame(list(zip(honda_attr.keys(), honda_attr.values())),columns =['attribute', 'frequency'])\n",
    "honda_attr = honda_attr.sort_values(by = 'frequency', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_attr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advice for product managers:\n",
    "\n",
    "The two top 5 brands that are highly associated with Honda are Fiat and Ford. Compared to Fiat and Ford, Honda has a relatively low lift score in the energy management and performance attributes. In order to become more competitive, Honda product managers should consider enhancing the performance and energy management aspects. \n",
    "\n",
    "Specifically, the Wordcloud (see below) for energy management-related comment contains the phrase “auxiliary low”. Thus, product managers should focus on fixing the problem on auxiliary of Honda’s products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Honda performance related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_performance_comment = []\n",
    "for j in range(len(honda_comment)):\n",
    "    for i in range(len(honda_comment[j])):\n",
    "        if honda_comment[j][i] in attributes.performance.dropna().tolist():\n",
    "            honda_performance_comment.append(list(set(honda_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_performance_list = []\n",
    "for i in range(len(honda_performance_comment)):\n",
    "    for j in range(len(honda_performance_comment[i])):\n",
    "        honda_performance_list.append(honda_performance_comment[i][j])\n",
    "text = ' '.join(honda_performance_list).lower()\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Honda energy_management related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_energy_management_comment = []\n",
    "for j in range(len(honda_comment)):\n",
    "    for i in range(len(honda_comment[j])):\n",
    "        if honda_comment[j][i] in attributes.energy_management.dropna().tolist():\n",
    "            honda_energy_management_comment.append(list(set(honda_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_energy_management_list = []\n",
    "for i in range(len(honda_energy_management_comment)):\n",
    "    for j in range(len(honda_energy_management_comment[i])):\n",
    "        honda_energy_management_list.append(honda_energy_management_comment[i][j])\n",
    "text = ' '.join(honda_energy_management_list).lower()\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advices for marketing/advertising managers:\n",
    "\n",
    "One of the most important features of Honda is that the brand is considered to be very cost-efficient. The lift score for the cost-efficient attribute is the highest among all the top 5 brands. Since this is a forum on trade-in values, we can consider Honda to have a relatively high trade-in value among the top 5 brands. The marketing campaign can focus on this attribute. Honda is also strongly associated with the attributes: comfort and interior and sound. However, as discussed above it is considered to be a low-end brand. Thus with a small budget, the buyer can get a really comfortable car with a nice interior. This proves that buying a Honda car is really a good deal. Thus, we believe the advertisement of Honda should definitely contain these key ideas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Honda comfort related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_comfort_comment = []\n",
    "for j in range(len(honda_comment)):\n",
    "    for i in range(len(honda_comment[j])):\n",
    "        if honda_comment[j][i] in attributes.comfort.dropna().tolist():\n",
    "            honda_comfort_comment.append(list(set(honda_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_comfort_list = []\n",
    "for i in range(len(honda_comfort_comment)):\n",
    "    for j in range(len(honda_comfort_comment[i])):\n",
    "        honda_comfort_list.append(honda_comfort_comment[i][j])\n",
    "text = ' '.join(honda_comfort_list).lower()\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Chevrolet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_comment = []\n",
    "for comment in comment_copy:\n",
    "    if 'chevrolet' in comment:\n",
    "        chevrolet_comment.append(list(set(comment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_attr = defaultdict(int)\n",
    "for comment in chevrolet_comment:\n",
    "    for attr in detial_attributes:\n",
    "        if attr in comment:\n",
    "\n",
    "            chevrolet_attr[attr] +=1\n",
    "chevrolet_attr = pd.DataFrame(list(zip(chevrolet_attr.keys(), chevrolet_attr.values())),columns =['attribute', 'frequency'])\n",
    "chevrolet_attr = chevrolet_attr.sort_values(by = 'frequency', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_attr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advices for product managers:\n",
    "\n",
    "The brands that are highly associated with Chevrolet are Toyota and Ford. Compared to them, Chevrolet is relatively weak in interior and safety. Thus the product managers of Chevrolet should focus on enhancing the brand’s interior design and safety. One of the words that commonly appear in the Chevrolet Wordcloud is “frumpy”. People are considered Chevrolet to be old fashion. Thus product manager might need to focus more on the design of the car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chevrolet safety related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_safety_comment = []\n",
    "for j in range(len(chevrolet_comment)):\n",
    "    for i in range(len(chevrolet_comment[j])):\n",
    "        if chevrolet_comment[j][i] in attributes.safety.dropna().tolist():\n",
    "            chevrolet_safety_comment.append(list(set(chevrolet_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_safety_list = []\n",
    "for i in range(len(chevrolet_safety_comment)):\n",
    "    for j in range(len(chevrolet_safety_comment[i])):\n",
    "        chevrolet_safety_list.append(chevrolet_safety_comment[i][j])\n",
    "text = ' '.join(chevrolet_safety_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chevrolet interial related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_interior_sound_comment = []\n",
    "for j in range(len(chevrolet_comment)):\n",
    "    for i in range(len(chevrolet_comment[j])):\n",
    "        if chevrolet_comment[j][i] in attributes.interior_sound.dropna().tolist():\n",
    "            chevrolet_interior_sound_comment.append(list(set(chevrolet_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_interior_sound_list = []\n",
    "for i in range(len(chevrolet_interior_sound_comment)):\n",
    "    for j in range(len(chevrolet_interior_sound_comment[i])):\n",
    "        chevrolet_interior_sound_list.append(chevrolet_interior_sound_comment[i][j])\n",
    "text = ' '.join(chevrolet_interior_sound_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Advices for marketing/advertising managers:\n",
    "\n",
    "Like Honda, Chevrolet is also considered to be cost-efficient. The phrase “good resell” has appeared in Wordcloud several times. Thus, the marketing team should definitely focus on the resell value of Chevrolet. Notably, in the performance Wordcloud, the word “snow” appears multiple times. Chevrolet performs well in snow weather. Thus the marketing team should consider promoting more in the snowy region such as Michigan and Montreal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chevrolet performance related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_performance_comment = []\n",
    "for j in range(len(chevrolet_comment)):\n",
    "    for i in range(len(chevrolet_comment[j])):\n",
    "        if chevrolet_comment[j][i] in attributes.performance.dropna().tolist():\n",
    "            chevrolet_performance_comment.append(list(set(chevrolet_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chevrolet_performance_list = []\n",
    "for i in range(len(chevrolet_performance_comment)):\n",
    "    for j in range(len(chevrolet_performance_comment[i])):\n",
    "        chevrolet_performance_list.append(chevrolet_performance_comment[i][j])\n",
    "text = ' '.join(chevrolet_performance_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Toyota"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_comment = []\n",
    "for comment in comment_copy:\n",
    "    if 'toyota' in comment:\n",
    "        toyota_comment.append(list(set(comment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_attr = defaultdict(int)\n",
    "for comment in toyota_comment:\n",
    "    for attr in detial_attributes:\n",
    "        if attr in comment:\n",
    "\n",
    "            toyota_attr[attr] +=1\n",
    "toyota_attr = pd.DataFrame(list(zip(toyota_attr.keys(), toyota_attr.values())),columns =['attribute', 'frequency'])\n",
    "toyota_attr = toyota_attr.sort_values(by = 'frequency', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_attr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advice for product managers:\n",
    "\n",
    "Toyota is strongly associated with Chevrolet and Fiat. Compared to these two brands, Toyota does not have a strong performance and energy management. Closely examining the Wordclouds generated based on the performance and energy management comment, we found the word “engine” keeps showing up. Also, people mentioned GMC Denali, a very high-performance truck, while discussing Toyota’s energy management. These suggest that Toyota’s product managers really should focus on developing products that can provide better performance and energy management. Moreover, like Honda, Toyota is considered to be a low-end brand. For possible market expansion, the product managers might explore the possibility of developing more high-end models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toyota performance related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_performance_comment = []\n",
    "for j in range(len(toyota_comment)):\n",
    "    for i in range(len(toyota_comment[j])):\n",
    "        if toyota_comment[j][i] in attributes.performance.dropna().tolist():\n",
    "            toyota_performance_comment.append(list(set(toyota_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_performance_list = []\n",
    "for i in range(len(toyota_performance_comment)):\n",
    "    for j in range(len(toyota_performance_comment[i])):\n",
    "        toyota_performance_list.append(toyota_performance_comment[i][j])\n",
    "text = ' '.join(toyota_performance_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toyota energy_management related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_energy_management_comment = []\n",
    "for j in range(len(toyota_comment)):\n",
    "    for i in range(len(toyota_comment[j])):\n",
    "        if toyota_comment[j][i] in attributes.energy_management.dropna().tolist():\n",
    "            toyota_energy_management_comment.append(list(set(toyota_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_energy_management_list = []\n",
    "for i in range(len(toyota_energy_management_comment)):\n",
    "    for j in range(len(toyota_energy_management_comment[i])):\n",
    "        toyota_energy_management_list.append(toyota_energy_management_comment[i][j])\n",
    "text = ' '.join(toyota_energy_management_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advices for marketing/advertising managers:\n",
    "\n",
    "One of the attributes that are strongly associated with Toyota is comfort. Based on the Wordcloud analysis, people mentioned drive space and big navigator. People consider it to be low-end but fancy enough. Thus we consider Toyota to be a family-friendly car brand because with a limited budget one can get a fancy enough and spacious car. The marketing direction should focus on building a family-friendly image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toyota comfort related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_comfort_comment = []\n",
    "for j in range(len(toyota_comment)):\n",
    "    for i in range(len(toyota_comment[j])):\n",
    "        if toyota_comment[j][i] in attributes.comfort.dropna().tolist():\n",
    "            toyota_comfort_comment.append(list(set(toyota_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyota_comfort_list = []\n",
    "for i in range(len(toyota_comfort_comment)):\n",
    "    for j in range(len(toyota_comfort_comment[i])):\n",
    "        toyota_comfort_list.append(toyota_comfort_comment[i][j])\n",
    "text = ' '.join(toyota_comfort_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Ford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_comment = []\n",
    "for comment in comment_copy:\n",
    "    if 'ford' in comment:\n",
    "        ford_comment.append(list(set(comment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_attr = defaultdict(int)\n",
    "for comment in ford_comment:\n",
    "    for attr in detial_attributes:\n",
    "        if attr in comment:\n",
    "\n",
    "            ford_attr[attr] +=1\n",
    "ford_attr = pd.DataFrame(list(zip(ford_attr.keys(), ford_attr.values())),columns =['attribute', 'frequency'])\n",
    "ford_attr = ford_attr.sort_values(by = 'frequency', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_attr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advices for product managers:\n",
    "The brands that are highly associated with Ford are Volkswagen and Subaru. Compared with other brands, Ford is considered to be safer. Thus the product manager should realize this strength and keep the current advantage. However, the product manager should also pay attention to the appearance of the vehicles. According to the text visualization, some words such as ‘frumpy’ and ‘look’ appear frequently, showing that the interior design could be adjusted to further improve the quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ford safety related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_safety_comment = []\n",
    "for j in range(len(ford_comment)):\n",
    "    for i in range(len(ford_comment[j])):\n",
    "        if ford_comment[j][i] in attributes.safety.dropna().tolist():\n",
    "            ford_safety_comment.append(list(set(ford_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_safety_list = []\n",
    "for i in range(len(ford_safety_comment)):\n",
    "    for j in range(len(ford_safety_comment[i])):\n",
    "        ford_safety_list.append(ford_safety_comment[i][j])\n",
    "text = ' '.join(ford_safety_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ford appearance related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_appearance_comment = []\n",
    "for j in range(len(ford_comment)):\n",
    "    for i in range(len(ford_comment[j])):\n",
    "        if ford_comment[j][i] in attributes.appearance.dropna().tolist():\n",
    "            ford_appearance_comment.append(list(set(ford_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_appearance_list = []\n",
    "for i in range(len(ford_appearance_comment)):\n",
    "    for j in range(len(ford_appearance_comment[i])):\n",
    "        ford_appearance_list.append(ford_appearance_comment[i][j])\n",
    "text = ' '.join(ford_appearance_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advices for marketing/advertising managers:\n",
    "\n",
    "Similar to Honda and Chevrolet, Ford is also considered to be cost-efficient. According to Wordcloud, people usually describe Ford to be a good deal, and suitable for ‘commuting’. Thus, the marketing team should potentially adjust the market positioning strategy accordingly and focus more on those people with higher demand on daily commuting. In addition, Ford brings comfort to drivers, showing it is also suitable for short business trips by car. Thus, the market team should consider promoting more advertisements in the business district."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ford performance related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_peformance_comment = []\n",
    "for j in range(len(ford_comment)):\n",
    "    for i in range(len(ford_comment[j])):\n",
    "        if ford_comment[j][i] in attributes.appearance.dropna().tolist():\n",
    "            ford_peformance_comment.append(list(set(ford_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ford_performance_list = []\n",
    "for i in range(len(ford_peformance_comment)):\n",
    "    for j in range(len(ford_peformance_comment[i])):\n",
    "        ford_performance_list.append(ford_peformance_comment[i][j])\n",
    "text = ' '.join(ford_performance_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Fiat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_comment = []\n",
    "for comment in comment_copy:\n",
    "    if 'fiat' in comment:\n",
    "        fiat_comment.append(list(set(comment)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_attr = defaultdict(int)\n",
    "for comment in fiat_comment:\n",
    "    for attr in detial_attributes:\n",
    "        if attr in comment:\n",
    "\n",
    "            fiat_attr[attr] +=1\n",
    "fiat_attr = pd.DataFrame(list(zip(fiat_attr.keys(), fiat_attr.values())),columns =['attribute', 'frequency'])\n",
    "fiat_attr = fiat_attr.sort_values(by = 'frequency', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_attr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advices for product managers:\n",
    "\n",
    "The brands that are highly associated with Fiat are Nissan and BMW. But by the text visualization, people mention ‘damage’ and ‘accident’ frequently. So Fiat’s product manager should definitely focus on improving driving safety, and the tire value, in particular. In addition, customers seem to appreciate those electrical vehicles more, compared with those ones involving traditional gas for energy. In this case, the product manager should also concentrate on the product transformation, and produce more vehicles popular among customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fiat safety related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_safety_comment = []\n",
    "for j in range(len(fiat_comment)):\n",
    "    for i in range(len(fiat_comment[j])):\n",
    "        if fiat_comment[j][i] in attributes.safety.dropna().tolist():\n",
    "            fiat_safety_comment.append(list(set(fiat_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_safety_list = []\n",
    "for i in range(len(fiat_safety_comment)):\n",
    "    for j in range(len(fiat_safety_comment[i])):\n",
    "        fiat_safety_list.append(fiat_safety_comment[i][j])\n",
    "text = ' '.join(fiat_safety_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fiat energy_management related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_energy_management_comment = []\n",
    "for j in range(len(fiat_comment)):\n",
    "    for i in range(len(fiat_comment[j])):\n",
    "        if fiat_comment[j][i] in attributes.energy_management.dropna().tolist():\n",
    "            fiat_energy_management_comment.append(list(set(fiat_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_energy_management_list = []\n",
    "for i in range(len(fiat_energy_management_comment)):\n",
    "    for j in range(len(fiat_energy_management_comment[i])):\n",
    "        fiat_energy_management_list.append(fiat_energy_management_comment[i][j])\n",
    "text = ' '.join(fiat_energy_management_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advices for marketing/advertising managers:\n",
    "\n",
    "According to Wordcloud, customers value the vehicle's appearance a lot by frequently mentioning the pretty colors and the right size for the garage. Thus, the marketing manager should emphasize the well-designed outlook and its convenience for crowded places. Moreover, similar to Chevrolet, Fiat is considered to be a ‘snow brother’ and is appreciated for its suitability for driving on snow. In this case, the advertising team should invest more in those snowy regions in the north.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fiat performance related comment visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_performance_comment = []\n",
    "for j in range(len(fiat_comment)):\n",
    "    for i in range(len(fiat_comment[j])):\n",
    "        if fiat_comment[j][i] in attributes.performance.dropna().tolist():\n",
    "            fiat_performance_comment.append(list(set(fiat_comment[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fiat_performance_list = []\n",
    "for i in range(len(fiat_performance_comment)):\n",
    "    for j in range(len(fiat_performance_comment[i])):\n",
    "        fiat_performance_list.append(fiat_performance_comment[i][j])\n",
    "text = ' '.join(fiat_performance_list).lower()\n",
    "\n",
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "n_list = [word for word, pos in tags if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS')]\n",
    "\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]\n",
    "n_string=(\" \").join(n_list)\n",
    "adj_string=(\" \").join(adj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(n_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud1 = WordCloud().generate(adj_string)\n",
    "plt.imshow(wordcloud1, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task: Discover the most aspirational brand in the discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The definition of the aspirational brand found from literature search:\n",
    "\n",
    "The aspirational brand means which brand:\n",
    "\n",
    "    1) People want to own, but not already owned for now\n",
    "    2) And the motivation of wants should be related to the brand's emotional value.\n",
    "    3) It should be achievable (to delineate the concept from just 'luxurious' brands)\n",
    "\n",
    "But the third definition can not be described from the current dataset; in field research, the survey method is usually utilized to distinguish an aspirational brand from a luxury brand. (reference: I've Wanted A BMW Since I Was A Kid: An Exploratory Analysis Of The Aspirational Brand, 2015, The Journal of Applied Business Research) Therefore, I decided to focus on finding the set of terms that can serve the definition no.1 and no.2. \n",
    "\n",
    "\n",
    "Methodology (Steps)\n",
    "\n",
    "* to define 'aspirational words' in the given dataset\n",
    "\n",
    "    * scope to 'adj' words using nltk tagging\n",
    "    * using VADER, gauge positive score of each word\n",
    "    * filter only with positivity score is greater than 0.5\n",
    "    * manually delete irrelevant words from positive word set\n",
    "    * manually delete functional positivity words from positive word set\n",
    "        * positive word set consists of 'functional positivity (including 'value for money\" and 'emotional positivity' - I decided to keep only 'emotional' part.\n",
    "    \n",
    "* With the derived aspirational list of words, calculate lift value for the top 10 brands.\n",
    "   * only keep rows whose lift value is greater than 1 \n",
    "* From the lift scores, calculate 'average lift' with aspirational terms per brand.\n",
    "* The brand shows the highest mean of lifts among aspirational terms is the most aspirational brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "for i in range(len(target_comment)):\n",
    "    for j in range(len(target_comment[i])):\n",
    "        wordlist.append(target_comment[i][j])\n",
    "text = ' '.join(wordlist).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "adj_list = [word for word, pos in tags if (pos == 'JJ' or pos == 'JJR' or pos == 'JJS' or pos =='RB' or pos =='RBR'\n",
    "                                          or pos =='RBS')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define aspiration word set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using VADER, gauge positive score of each word \n",
    "#and narrow down the words of interest with positivity score is greater than 0.5\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sent = SentimentIntensityAnalyzer() \n",
    "#sent.polarity_scores('like')\n",
    "\n",
    "pos_word_dict = {} \n",
    "for i in adj_list: #adj_list\n",
    "    if sent.polarity_scores(i)['pos'] > 0.5:  #filter with positivity score > 0.5\n",
    "        pos_word_dict[i] = sent.polarity_scores(i)['pos']\n",
    "        #print(i, sent.polarity_scores(i), sent.polarity_scores(i)['pos'])\n",
    "    \n",
    "#pos_word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_list = list(pos_word_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminate irrelevant words from pos_list\n",
    "irr_list = ['ha','thanks-', 'well-', 'yay','hug','pray', 'truer','fiestas','gl','fresh', 'bless','smile', 'admit', 'sure', 'highlight','grant','forgiveness', 'agree', 'forgive', 'popular','thank', 'generous', 'clear', 'silly', 'curious', 'certainly', 'welcome', 'yeah', 'peculiar', 'definitely', 'luckily', 'honest', 'nicely', 'certain', 'straight', 'ok', 'honesty', 'create', 'please', 'win', 'grey', 'true', 'honestly', 'convince', 'ready', 'thankfully', 'dear', 'kiss', 'gently', 'yes', 'truly', 'extend', 'strongly', 'hopefully', 'carefully', 'important', 'matter', 'friendly', 'tx', 'tia', 'substantial', 'courtesy', 'clearly', 'respectively', 'greater', 'allow', 'join', 'humorous', 'treat', 'definite', 'funny', 'friend', 'greet', 'optimistically', 'gla', 'agreeable', 'invite', 'lol', 'surprise', 'sigh', 'apologize', 'excuse', 'ly', 'sunny', 'god', 'acceptable', 'okay', 'yep', 'casually', 'ftw', 'alert', 'hilarious', 'accept', 'sincerely', 'importantly', 'respectfully', 'nh', 'laugh', 'goodness', 'reach', 'positively', 'resolve', 'luckier', 'natural', 'fyi', 'thx', 'friends', 'surprisingly', 'truthfully', 'surely', 'truth', 'relieve', 'haha']\n",
    "pos_list = [item for item in pos_list if item not in irr_list]\n",
    "\n",
    "#eliminate functional positivity related words\n",
    "func_list = ['prevent','support','adopt','clean','solve','tolerance','incentive', 'huge', 'helpful', 'easily', 'comfortable','scoop', 'profitable', 'protect', 'defensive', 'careful', 'easier', 'fit', 'smart', 'gt', 'freeway', 'care', 'easy', 'recommend', 'safe', 'casual', 'solid', 'save', 'responsible', 'useful', 'efficient', 'benefit', 'legal', 'stealthily', 'effectively', 'improve', 'reward', 'capable', 'healthy', 'effective', 'stable', 'powerful', 'easiest', 'comprehensive', 'warm', 'help', 'safely', 'faithful', 'incentives', 'painless', 'cleaner', 'mandatory']\n",
    "pos_list = [item for item in pos_list if item not in func_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspirations = pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(aspirations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate lift value for the combination of aspiration terms and the top 10 brands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make combination of Top 10 Brand and aspirations\n",
    "import itertools\n",
    "comb = list(itertools.product(top_10,aspirations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Brand frequency\n",
    "brand_dict = {}\n",
    "for (key, value) in brand_frequency.items():\n",
    "    if key in top_10:\n",
    "        brand_dict[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate aspirational words' mentioned frequency\n",
    "asp_frequency = defaultdict(int)\n",
    "for comment in processed_text: \n",
    "    for words in comment: \n",
    "        if words in aspirations:\n",
    "            asp_frequency[words]+=1\n",
    "\n",
    "#asp_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the #(A,B); pair frequency\n",
    "pair_frequency = defaultdict(int)\n",
    "for pair in comb:\n",
    "    for comm in target_comment_distinct:\n",
    "        if pair[0] in comm and pair[1] in comm:\n",
    "            pair_frequency[pair] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate 'liftA'; lift values for aspirations - brands\n",
    "liftA = {}\n",
    "for i in pair_frequency.keys():\n",
    "    #print(pair_frequency[i], brand_dict[i[0]], asp_frequency[i[1]])\n",
    "    liftA[i] = i[0], (5000*pair_frequency[i]) / (brand_dict[i[0]]*asp_frequency[i[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep rows whose lift value > 1 \n",
    "df_A = pd.DataFrame.from_dict(liftA, orient='index', columns=['brand','lift'])\n",
    "df_A.sort_values(ascending = True, by = 'lift').head(30)\n",
    "df_A = df_A[df_A.lift > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out the most aspirational brand - utilizing mean of aspirational lifts per brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate 'average lift' with aspirational terms per brand\n",
    "df_asp = df_A.groupby('brand').mean().sort_values(ascending = False, by = 'lift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out the most aspirational brand\n",
    "print('\\n \\033[1m' + 'Subaru is the \"Most Aspirational\" Brand ' + '\\033[0m')\n",
    "print('\\n Brands and Lift Values:')\n",
    "display(df_asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the research, we could prove that the high aspirational orientation was actually realized as the market performance of the brand. From the below chart, we can see that the units sold of Subra in the United States from 2001 to 2019 ( IHS Global Intelligence - Automotive Market Database (released in April, 2019)) soared with 8% of CAGR. Segment-wise, the SUV(Sports Utility Vehicle) models are in orange colours, and the sedan models are in green colours. We can also find out that Subaru’s new car sales are leveraged by SUV models significantly; in 2019, SUV models accounted for more than half of Subaru’s annual sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, connected to the terms such as ‘enjoyable,’ which Subaru showed the maximum lift among brands, we can infer that from 2001 to 2019, the direction of aspirations changed from family sedans to sporty vehicles in the United States passenger car market, as shown in the historical new car sales broken down into segment in the chart. (IHS Global Intelligence - Automotive Market Database (released in April, 2019))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, Subaru’s SUV portfolios successfully positioned in growing sporty vehicles demand in the United States, and it led to the high aspirational orientation in consumer’s perception and turned out to increase in sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
